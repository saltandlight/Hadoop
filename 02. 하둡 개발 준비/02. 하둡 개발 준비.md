# 02. 하둡 개발 준비

## 2.1 실행모드 결정

- 독립실행(Standalone) 모드:

  하나의 하둡만 실행시킴, 확장도 안 됨 

  완벽한 세팅은 아님 

- 가상 분산(Pseudo-distributed) 모드: 하나의 컴퓨터 안에 하나의 하둡만 설치, 향후 여

  ​                                                          러 서버와 연동 -> 확장 가능

- 완전 분산

## 2.2 리눅스 서버 준비

![cap2](cap2.PNG)

- client.jar도 갖다놓기 
- ssh-keygen -t dsa -P 
- //중간에 password 물어보는 거 안 하게 하려고 하는 것

## 2.8 SSH 설정

공개키는 사용자 계정의 홈 디렉터리의 .ssh 폴더에 생성됨.

생성된 공개키를 ssh-copy-id 명령어를 이용해서 다른 서버에 복사 -> ssh-copy-id 명령어는 대상 서버의 .ssh 디렉터리 안에 있는 authrorized_keys 파일에 공개키를 입력

-> 다음과 같은 형식으로 실행

```linux
[root@hadoopserver1 ~]# ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
Generating public/private dsa key pair.
Your identification has been saved in /root/.ssh/id_dsa.
Your public key has been saved in /root/.ssh/id_dsa.pub.
The key fingerprint is:
f9:ea:14:e6:ef:04:23:21:d4:75:7f:3a:92:2b:4c:fb root@hadoopserver1
The key's randomart image is:
+--[ DSA 1024]----+
|    .. .. .      |
|   .  .  . .     |
|    . .     . .  |
|     . . . . o   |
|      . S o o    |
|       * * o .   |
|        * +      |
|       . *       |
|       .o.E      |
+-----------------+
[root@hadoopserver1 ~]# ls -a
.              .bashrc   .esd_auth       .swt             공개      서식
..             .cache    .local          .tcshrc          다운로드  음악
.ICEauthority  .config   .mozilla        anaconda-ks.cfg  문서
.bash_history  .cshrc    .mysql_history  bamboologs       바탕화면
.bash_logout   .dbus     .p2             file             비디오
.bash_profile  .eclipse  .ssh            shell            사진
[root@hadoopserver1 ~]# cd .ssh
[root@hadoopserver1 .ssh]# ls
id_dsa  id_dsa.pub  known_hosts
[root@hadoopserver1 .ssh]# more id_dsa
-----BEGIN DSA PRIVATE KEY-----
MIIBuwIBAAKBgQCydKP5Tk31EsrdIZVsv/RpQkoZTUrGFMdzSOc7OiF6uCAn5X95
0OcSvA+GXfqmo6tf0nJNVq47OcFmDbb/VZ7yOFIO9HfIlX884pHMXz9lcQjEbn2U
CxtdZ+ALEmbK2kYLpWnmCjjC6ppySjTyl7MqBn1Z98BLA5GYu+FEjuDcrwIVALmr
C2naMywMVBA4ZjVoigKh8S/DAoGAAVYKRMF/Y8qXdX1Km8Ky394ycFX6oOtyDAFk
FRQYTED3DUpiUQQP8fOhNOfNxWE6nylC4OnCCRvOTJOmMrVciyy8OxOrYjQr3nwZ
P6X6FvNHAkDo+APx6gFC66YP5rsw8ZZYquPW1OJCtrptCrzDGzyr1/WGOjkS4a5+
p06U2WwCgYAT3JOXnPO8uBunC/obnRSBGhqxe/0oC461FoBGDDfvp/teIOd1kh9p
swYtD4zlfTB44ZAeg5ds3H1omLK9fRpNzcJCx6nsEfsaODFsIsRTR/FIjsdAvQL/
oEHkgzrsTPUi0lLJPziUKmIrE0UQoPAgVVzBJ71WchjbkViIoG99ogIVAIUVDVN1
c7/7wxHqgfHz1QrjitdV
-----END DSA PRIVATE KEY-----
[root@hadoopserver1 .ssh]# more id_pub
id_pub: 그런 파일이나 디렉터리가 없습니다
[root@hadoopserver1 .ssh]# ls
id_dsa  id_dsa.pub  known_hosts
[root@hadoopserver1 .ssh]# cat id_dsa.pub >> authorized_keys
[root@hadoopserver1 .ssh]# ls
authorized_keys  id_dsa  id_dsa.pub  known_hosts
[root@hadoopserver1 .ssh]# cd
[root@hadoopserver1 ~]# ssh hadoopserver1
Last login: Mon Aug  5 14:03:17 2019 from hadoopserver1
```

나중에 다른 컴퓨터에 들어갈 때도 키를 물어봄

## 2.10 하둡 환경설정 파일 수정

firewall 중지

```linux 
systemctl disable firewalld 
```

- conf/core-site.xml 수정

```linux
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!-- Put site-specific property overrides in this file. -->

<configuration>
<property>
  <name>fs.default.name</name>
  <value>hdfs://localhost:9000</value>
</property>
<property>
  <name>dfs.tmp.dir</name>
  <value>/etc/hadoop-1.2.1/tmp</value>
</property>
</configuration>
```

- conf/hdfs-site.xml

```linux
 
<configuration>
<property>
  <name>dfs.replication</name>
  <value>1</value>
</property>
<property>
  <name>dfs.name.dir</name>
  <value>/usr/local/hadoop/name</value>
</property>
<property>
  <name>dfs.data.dir</name>
  <value>/usr/local/hadoop/data</value>
</property>
<property>
  <name>dfs.webhdfs.enabled</name>
  <value>true</value>
</property>
</configuration>
```

- conf/hdfs-site.xml

``` linux
 
<configuration>
<property>
  <name>dfs.replication</name>
  <value>1</value>
</property>
<property>
  <name>dfs.name.dir</name>
  <value>/usr/local/hadoop/name</value>
</property>
<property>
  <name>dfs.data.dir</name>
  <value>/usr/local/hadoop/data</value>
</property>
<property>
  <name>dfs.webhdfs.enabled</name>
  <value>true</value>
</property>
</configuration>
```

- conf/mapred-site.xml

```linux
<configuration>
<property>
  <name>mapred.job.tracker</name>
  <value>localhost:9001</value>
</property>
</configuration>
[출처] Hadoop 설치 (비공개 카페)
```

- bashrc 수정

```linux
. /etc/hadooop-1.2.1/conf/hadoop-env.sh
```

- /etc/profile

```linux
# /etc/profile

# System wide environment and startup programs, for login setup
# Functions and aliases go in /etc/bashrc

# It's NOT a good idea to change this file unless you know what you
# are doing. It's much better to create a custom.sh shell script in
# /etc/profile.d/ to make custom changes to your environment, as this
# will prevent the need for merging in future updates.

pathmunge () {
    case ":${PATH}:" in
        *:"$1":*)
            ;;
        *)
            if [ "$2" = "after" ] ; then
                PATH=$PATH:$1
            else
                PATH=$1:$PATH
            fi
    esac
}


if [ -x /usr/bin/id ]; then
    if [ -z "$EUID" ]; then
        # ksh workaround
        EUID=`id -u`
        UID=`id -ru`
    fi
    USER="`id -un`"
    LOGNAME=$USER
    MAIL="/var/spool/mail/$USER"
fi

# Path manipulation
if [ "$EUID" = "0" ]; then
    pathmunge /usr/sbin
    pathmunge /usr/local/sbin
else
    pathmunge /usr/local/sbin after
    pathmunge /usr/sbin after
fi

HOSTNAME=`/usr/bin/hostname 2>/dev/null`
HISTSIZE=1000
if [ "$HISTCONTROL" = "ignorespace" ] ; then
    export HISTCONTROL=ignoreboth
else
    export HISTCONTROL=ignoredups
fi


JAVA_HOME=/etc/jdk1.8
export JAVA_HOME
CLASSPATH=$JAVA_HOME/lib
export CLASSPATH
 
ECLIPSE_HOME=/etc/eclipse
export ECLIPSE_HOME
 
 
TOMCAT_HOME=/etc/tomcat
export TOMCAT_HOME

HADOOP_HOME=/etc/hadoop-1.2.1
PATH=.:$JAVA_HOME/bin:$TOMCAT_HOME/bin:$HADOOP_HOME/bin:$PATH


export PATH USER LOGNAME MAIL HOSTNAME HISTSIZE HISTCONTROL

# By default, we want umask to get set. This sets it for login shell
# Current threshold for system reserved uid/gids is 200
# You could check uidgid reservation validity in
# /usr/share/doc/setup-*/uidgid file
if [ $UID -gt 199 ] && [ "`id -gn`" = "`id -un`" ]; then
    umask 002
else
    umask 022
fi

for i in /etc/profile.d/*.sh ; do
    if [ -r "$i" ]; then
        if [ "${-#*i}" != "$-" ]; then 
            . "$i"
        else
            . "$i" >/dev/null
        fi
    fi
done

unset i
unset -f pathmunge
```

- format

```linux
hadoop namenode -format
```

- start-all.sh
- jps

```linux 
[root@hadoopserver1 hadoop-1.2.1]# jps
5155 SecondaryNameNode
2451 NameNode
5337 TaskTracker
5018 DataNode
2733 JobTracker
5550 Jps
```

디렉터리 생성되었는지 확인하기 